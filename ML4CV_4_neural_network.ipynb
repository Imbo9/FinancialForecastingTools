{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywawXTDXzSCN"
      },
      "source": [
        "We start with our usual imports and figure adjustments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Iiy4LlS5xD7J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from timeit import default_timer as timer\n",
        "from functools import partial\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
        "plt.rcParams['font.size'] = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwsd_5l0LPQI"
      },
      "source": [
        "Then we load CIFAR10, and we create the usual `Dataset`s and `DataLoader`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "f7d26e03efd0493687150edb694b61e4",
            "119b429102b64b92b70e485fec445730",
            "1c08781342a548eb9d9ed8a97583caa8",
            "e8430ea02b2c44069a81c467c6d31b1d",
            "fcbc3ec15c094c38b4ceb7841dc39011",
            "1c042763bc8d47b39331698febf3da11",
            "b673b35ac1bb450b98a3579474917b31",
            "05e3a49575ec4f5cb99884756b3be1d2",
            "90ce6a95de24450f8c365a3cfbf4db72",
            "787603d3b0b14f91bdf68c45e7eb5fa2",
            "2aa8fd2ddd054b44825b5908f29510db"
          ]
        },
        "id": "JXNjkzQBzW6x",
        "outputId": "c19f3758-f964-40a5-a814-d4f913bfca26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "tsfms = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda z: z.reshape(-1))])\n",
        "train_ds = torchvision.datasets.CIFAR10(root=\"/data/\", train=True, transform=tsfms, download=True)\n",
        "test_ds = torchvision.datasets.CIFAR10(root=\"/data/\", train=False, transform=tsfms)\n",
        "\n",
        "classes = train_ds.classes\n",
        "n_classes = len(classes)\n",
        "n_features = len(train_ds[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X9QK1XnpzZWx"
      },
      "outputs": [],
      "source": [
        "splitted_datasets = torch.utils.data.random_split(train_ds, [45000, 5000])\n",
        "actual_train_subds = splitted_datasets[0]\n",
        "valid_subds = splitted_datasets[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DSJRHzdOzbUC"
      },
      "outputs": [],
      "source": [
        "small_actual_train_subds = torch.utils.data.Subset(actual_train_subds, range(500))\n",
        "small_valid_subds = torch.utils.data.Subset(valid_subds, range(100))\n",
        "small_test_subds = torch.utils.data.Subset(test_ds, range(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DLBTTtEpzfDR"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "small_actual_train_dl = torch.utils.data.DataLoader(small_actual_train_subds, batch_size=batch_size, shuffle=True)\n",
        "small_valid_dl = torch.utils.data.DataLoader(small_valid_subds, batch_size=batch_size)\n",
        "small_test_dl = torch.utils.data.DataLoader(small_test_subds, batch_size=batch_size)\n",
        "actual_train_dl = torch.utils.data.DataLoader(actual_train_subds, batch_size=batch_size, shuffle=True)\n",
        "valid_dl = torch.utils.data.DataLoader(valid_subds, batch_size=batch_size)\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLnPsp6DLbaP"
      },
      "source": [
        "We will then create our first Neural Network. One way to create Neural Networks in PyTorch is by subclassing `torch.nn.Module`. In this way, our model will inherit a lot of ready-to-use convinience functions (access to parameters for optimization, get/set parameters, ...).\n",
        "\n",
        "We only need to create the layers we will use in the `__init__` function and define the `forward` function that specifies how to apply them.\n",
        "\n",
        "Layers are in turn subclasses of `torch.nn.Module`. In our example, we will use only linear layers, i.e. Fully Connected (FC) layers. Our network will have at least two FC layers: `self.first`, mapping the flattened input image into the (first) hidden representation, and `self.last`, mapping the (last) hidden representation into the scores for the classes.\n",
        "\n",
        "To play with varying depths and activation functions, we will have two additional parameters:\n",
        "\n",
        "\n",
        "*   `n_additional_hidden_layers`, specifies how many hidden layers our network has, beside `self.first`\n",
        "*   `use_relu`, if `False`, activations will be sigmoid functions, ReLUs otherwise\n",
        "\n",
        "Note that to store a variable number of layers in our network, we do not use plain PyTorch lists, but `torch.nn.ModuleList`. This is important to make PyTorch aware of the layers in the list, e.g. to set/get their parameters when calling the methods of the base `Module` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2nbo9Igi2Lr5"
      },
      "outputs": [],
      "source": [
        "class TwoPlusLayersNetwork(torch.nn.Module):\n",
        "  def __init__(self, n_features, hidden_width, n_classes, n_additional_hidden_layers=0, use_relu=True):\n",
        "    super(TwoPlusLayersNetwork, self).__init__()\n",
        "    self.first = torch.nn.Linear(n_features, hidden_width)\n",
        "    self.activation = torch.relu if use_relu else torch.sigmoid\n",
        "    self.last = torch.nn.Linear(hidden_width, n_classes)\n",
        "\n",
        "    self.additional_hidden_layers = torch.nn.ModuleList(\n",
        "        [torch.nn.Linear(hidden_width, hidden_width) for i in range(n_additional_hidden_layers)])\n",
        "\n",
        "    #initialization\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, torch.nn.Linear):\n",
        "        if use_relu:\n",
        "          torch.nn.init.kaiming_uniform_(m.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
        "        else:\n",
        "          torch.nn.init.xavier_uniform_(m.weight)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.first.forward(x)\n",
        "    x = self.activation(x)\n",
        "    for layer in self.additional_hidden_layers:\n",
        "      x = layer.forward(x)\n",
        "      x = self.activation(x)\n",
        "    x = self.last.forward(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izRXo7zLOYQk"
      },
      "source": [
        "We then define the usual function to train a model.\n",
        "\n",
        "Note that we use\n",
        "*   `nn.parameters()` to get a list of trainable parameters\n",
        "*   `nn.state_dict()` to get the model parameters when we achieve better validation accuracy and save them in the `best_params` variable.\n",
        "\n",
        "These are two of the convinience functions our network inherits from `torch.nn.Module`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VddQeQtZ2zcv"
      },
      "outputs": [],
      "source": [
        "def ncorrect(scores, y):\n",
        "  y_hat = torch.argmax(scores, 1)\n",
        "  return (y_hat==y).sum()\n",
        "\n",
        "def accuracy(scores, y):\n",
        "  correct = ncorrect(scores, y)\n",
        "  return correct.true_divide(y.shape[0])\n",
        "\n",
        "def train_loop(n_features, hidden_width, n_classes, n_additional_hidden_layers, use_relu,\n",
        "               train_dl, epochs, partial_opt,\n",
        "               valid_dl=None, verbose=False):\n",
        "  best_valid_acc = 0\n",
        "  best_params = []\n",
        "  best_epoch = -1\n",
        "\n",
        "  nn = TwoPlusLayersNetwork(n_features, hidden_width, n_classes, n_additional_hidden_layers, use_relu).to(device)\n",
        "\n",
        "  # We \"complete\" the partial function by calling it and specifying the missing parameters\n",
        "  opt = partial_opt(nn.parameters())\n",
        "\n",
        "  for e in range(epochs):\n",
        "    #train\n",
        "    train_loss = 0\n",
        "    train_samples = 0\n",
        "    train_acc = 0\n",
        "    for train_data in train_dl:\n",
        "      inputs, labels = train_data[0].to(device), train_data[1].to(device)\n",
        "\n",
        "      scores = nn.forward(inputs)\n",
        "      loss = F.cross_entropy(scores, labels)\n",
        "      train_loss += loss.item() * inputs.shape[0]\n",
        "      train_samples += inputs.shape[0]\n",
        "      train_acc += ncorrect(scores, labels).item()\n",
        "      loss.backward()\n",
        "\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "\n",
        "    train_acc /= train_samples\n",
        "    train_loss /= train_samples\n",
        "\n",
        "    # validation\n",
        "    with torch.no_grad():\n",
        "      valid_loss = 0\n",
        "      valid_samples = 0\n",
        "      valid_acc = 0\n",
        "      if valid_dl is not None:\n",
        "        for valid_data in valid_dl:\n",
        "\n",
        "          inputs, labels = valid_data[0].to(device), valid_data[1].to(device)\n",
        "\n",
        "          valid_scores = nn.forward(inputs)\n",
        "          valid_loss += F.cross_entropy(valid_scores, labels).item() * inputs.shape[0]\n",
        "          valid_samples += inputs.shape[0]\n",
        "          valid_acc += ncorrect(valid_scores, labels).item()\n",
        "        valid_acc /= valid_samples\n",
        "        valid_loss /= valid_samples\n",
        "\n",
        "      if valid_dl is None or valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc if valid_dl is not None else 0\n",
        "        best_params = nn.state_dict()\n",
        "        best_epoch = e\n",
        "\n",
        "\n",
        "    if verbose and e % 10 == 0:\n",
        "      print(f\"Epoch {e}: train loss {train_loss:.3f} - train acc {train_acc:.3f}\" + (\"\" if valid_dl is None else f\" - valid loss {valid_loss:.3f} - valid acc {valid_acc:.3f}\"))\n",
        "\n",
        "  if verbose and valid_dl is not None:\n",
        "    print(f\"Best epoch {best_epoch}, best acc {best_valid_acc}\")\n",
        "\n",
        "  return best_valid_acc, best_params, best_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pupldmv9ZaCe"
      },
      "source": [
        "The two functions are similar, but serve different purposes.\n",
        "\n",
        "`parameters()` returns a list (actually, a generator) of trainable tensors, which is what `Optimizer`s require: they do not need to know which tensor correspond to which layer, since they are all treated the same when performing SGD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4xBfqCeX5Ys",
        "outputId": "480db166-1cc1-4db2-e0ff-c990f337ee51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.nn.parameter.Parameter'> torch.Size([50, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([50])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 50])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([50, 50])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([50])\n"
          ]
        }
      ],
      "source": [
        "hidden_width = 50\n",
        "nn = TwoPlusLayersNetwork(n_features, hidden_width, n_classes, n_additional_hidden_layers=1, use_relu=True)\n",
        "for p in nn.parameters():\n",
        "  print(type(p), p.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNmyH3BfaFQo"
      },
      "source": [
        "`state_dict()` instead is an (Ordered) Dictionary, which associates each variable storing a layer in our classes with its parameters. It is therefore useful to obtain a snapshot of the parameters of our model that can later be restored by calling `load_state_dict()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW0_jwzAYUFB",
        "outputId": "a20f53db-0fec-4cdb-d0f4-5d215c404606"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "collections.OrderedDict"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(nn.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEIEOMH3YhyS",
        "outputId": "ebb4c459-c3c0-44ac-db3e-8520eb2218b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "odict_keys(['first.weight', 'first.bias', 'last.weight', 'last.bias', 'additional_hidden_layers.0.weight', 'additional_hidden_layers.0.bias'])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn.state_dict().keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j1uORe6YpBJ",
        "outputId": "ec43cb13-d39c-483b-ce1c-376d8584b43e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.0180,  0.0052,  0.0139, -0.0105, -0.0108,  0.0158, -0.0097, -0.0009,\n",
              "        -0.0046, -0.0017, -0.0159, -0.0073, -0.0169, -0.0115,  0.0169, -0.0065,\n",
              "         0.0158, -0.0052,  0.0081, -0.0075, -0.0062,  0.0034,  0.0023,  0.0174,\n",
              "         0.0093, -0.0079, -0.0119,  0.0161,  0.0129, -0.0045,  0.0158,  0.0039,\n",
              "         0.0175,  0.0127,  0.0158,  0.0157,  0.0009,  0.0030, -0.0024, -0.0043,\n",
              "         0.0021,  0.0159,  0.0047, -0.0154,  0.0025, -0.0077, -0.0096,  0.0031,\n",
              "         0.0121,  0.0042])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn.state_dict()[\"first.bias\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_gDTTNKUOHS"
      },
      "source": [
        "Let's verify that the use of the sigmoid as activation function makes it more difficult to train \"deep\" networks, i.e. with 10 hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s2xnpo73w5Q",
        "outputId": "9fe2add2-3281-4b7e-fb67-3c18b4ccb681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss 2.398 - train acc 0.110 - valid loss 2.416 - valid acc 0.100\n",
            "Epoch 10: train loss 2.303 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 20: train loss 2.298 - train acc 0.116 - valid loss 2.311 - valid acc 0.090\n",
            "Epoch 30: train loss 2.299 - train acc 0.110 - valid loss 2.308 - valid acc 0.090\n",
            "Epoch 40: train loss 2.300 - train acc 0.106 - valid loss 2.309 - valid acc 0.090\n",
            "Epoch 50: train loss 2.301 - train acc 0.100 - valid loss 2.305 - valid acc 0.100\n",
            "Epoch 60: train loss 2.301 - train acc 0.116 - valid loss 2.304 - valid acc 0.100\n",
            "Epoch 70: train loss 2.299 - train acc 0.116 - valid loss 2.307 - valid acc 0.090\n",
            "Epoch 80: train loss 2.299 - train acc 0.098 - valid loss 2.307 - valid acc 0.100\n",
            "Epoch 90: train loss 2.299 - train acc 0.116 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 100: train loss 2.300 - train acc 0.116 - valid loss 2.309 - valid acc 0.090\n",
            "Epoch 110: train loss 2.298 - train acc 0.116 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 120: train loss 2.299 - train acc 0.116 - valid loss 2.302 - valid acc 0.090\n",
            "Epoch 130: train loss 2.301 - train acc 0.116 - valid loss 2.308 - valid acc 0.100\n",
            "Epoch 140: train loss 2.299 - train acc 0.110 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 150: train loss 2.302 - train acc 0.116 - valid loss 2.301 - valid acc 0.090\n",
            "Epoch 160: train loss 2.299 - train acc 0.094 - valid loss 2.307 - valid acc 0.090\n",
            "Epoch 170: train loss 2.299 - train acc 0.116 - valid loss 2.306 - valid acc 0.100\n",
            "Epoch 180: train loss 2.299 - train acc 0.098 - valid loss 2.306 - valid acc 0.100\n",
            "Epoch 190: train loss 2.299 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 200: train loss 2.300 - train acc 0.116 - valid loss 2.309 - valid acc 0.090\n",
            "Epoch 210: train loss 2.299 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 220: train loss 2.298 - train acc 0.116 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 230: train loss 2.298 - train acc 0.116 - valid loss 2.303 - valid acc 0.090\n",
            "Epoch 240: train loss 2.298 - train acc 0.116 - valid loss 2.309 - valid acc 0.090\n",
            "Epoch 250: train loss 2.299 - train acc 0.108 - valid loss 2.304 - valid acc 0.100\n",
            "Epoch 260: train loss 2.299 - train acc 0.116 - valid loss 2.302 - valid acc 0.090\n",
            "Epoch 270: train loss 2.297 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 280: train loss 2.300 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 290: train loss 2.298 - train acc 0.104 - valid loss 2.303 - valid acc 0.110\n",
            "Epoch 300: train loss 2.300 - train acc 0.116 - valid loss 2.310 - valid acc 0.090\n",
            "Epoch 310: train loss 2.297 - train acc 0.116 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 320: train loss 2.300 - train acc 0.104 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 330: train loss 2.299 - train acc 0.116 - valid loss 2.303 - valid acc 0.090\n",
            "Epoch 340: train loss 2.299 - train acc 0.100 - valid loss 2.305 - valid acc 0.100\n",
            "Epoch 350: train loss 2.298 - train acc 0.116 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 360: train loss 2.299 - train acc 0.110 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 370: train loss 2.298 - train acc 0.116 - valid loss 2.303 - valid acc 0.090\n",
            "Epoch 380: train loss 2.299 - train acc 0.116 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 390: train loss 2.297 - train acc 0.116 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 400: train loss 2.298 - train acc 0.110 - valid loss 2.307 - valid acc 0.090\n",
            "Epoch 410: train loss 2.298 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 420: train loss 2.299 - train acc 0.116 - valid loss 2.302 - valid acc 0.090\n",
            "Epoch 430: train loss 2.298 - train acc 0.116 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 440: train loss 2.299 - train acc 0.110 - valid loss 2.303 - valid acc 0.100\n",
            "Epoch 450: train loss 2.298 - train acc 0.116 - valid loss 2.308 - valid acc 0.090\n",
            "Epoch 460: train loss 2.299 - train acc 0.116 - valid loss 2.302 - valid acc 0.090\n",
            "Epoch 470: train loss 2.298 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 480: train loss 2.300 - train acc 0.100 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 490: train loss 2.298 - train acc 0.098 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 500: train loss 2.298 - train acc 0.116 - valid loss 2.303 - valid acc 0.090\n",
            "Epoch 510: train loss 2.300 - train acc 0.116 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 520: train loss 2.298 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 530: train loss 2.298 - train acc 0.110 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 540: train loss 2.299 - train acc 0.116 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 550: train loss 2.298 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 560: train loss 2.298 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 570: train loss 2.299 - train acc 0.116 - valid loss 2.303 - valid acc 0.090\n",
            "Epoch 580: train loss 2.298 - train acc 0.116 - valid loss 2.308 - valid acc 0.090\n",
            "Epoch 590: train loss 2.298 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 600: train loss 2.299 - train acc 0.116 - valid loss 2.302 - valid acc 0.090\n",
            "Epoch 610: train loss 2.300 - train acc 0.106 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 620: train loss 2.298 - train acc 0.116 - valid loss 2.303 - valid acc 0.090\n",
            "Epoch 630: train loss 2.299 - train acc 0.116 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 640: train loss 2.300 - train acc 0.116 - valid loss 2.303 - valid acc 0.090\n",
            "Epoch 650: train loss 2.299 - train acc 0.116 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 660: train loss 2.298 - train acc 0.106 - valid loss 2.303 - valid acc 0.100\n",
            "Epoch 670: train loss 2.298 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 680: train loss 2.300 - train acc 0.110 - valid loss 2.306 - valid acc 0.100\n",
            "Epoch 690: train loss 2.300 - train acc 0.116 - valid loss 2.309 - valid acc 0.090\n",
            "Epoch 700: train loss 2.298 - train acc 0.100 - valid loss 2.304 - valid acc 0.100\n",
            "Epoch 710: train loss 2.299 - train acc 0.116 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 720: train loss 2.298 - train acc 0.116 - valid loss 2.309 - valid acc 0.090\n",
            "Epoch 730: train loss 2.297 - train acc 0.108 - valid loss 2.302 - valid acc 0.090\n",
            "Epoch 740: train loss 2.298 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 750: train loss 2.299 - train acc 0.116 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 760: train loss 2.298 - train acc 0.116 - valid loss 2.301 - valid acc 0.090\n",
            "Epoch 770: train loss 2.298 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 780: train loss 2.298 - train acc 0.116 - valid loss 2.308 - valid acc 0.090\n",
            "Epoch 790: train loss 2.298 - train acc 0.102 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 800: train loss 2.297 - train acc 0.116 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 810: train loss 2.300 - train acc 0.082 - valid loss 2.305 - valid acc 0.100\n",
            "Epoch 820: train loss 2.298 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 830: train loss 2.299 - train acc 0.116 - valid loss 2.303 - valid acc 0.090\n",
            "Epoch 840: train loss 2.298 - train acc 0.116 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 850: train loss 2.298 - train acc 0.104 - valid loss 2.308 - valid acc 0.100\n",
            "Epoch 860: train loss 2.299 - train acc 0.116 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 870: train loss 2.299 - train acc 0.116 - valid loss 2.303 - valid acc 0.090\n",
            "Epoch 880: train loss 2.300 - train acc 0.096 - valid loss 2.305 - valid acc 0.100\n",
            "Epoch 890: train loss 2.300 - train acc 0.110 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 900: train loss 2.299 - train acc 0.116 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 910: train loss 2.302 - train acc 0.076 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 920: train loss 2.301 - train acc 0.116 - valid loss 2.306 - valid acc 0.090\n",
            "Epoch 930: train loss 2.298 - train acc 0.116 - valid loss 2.304 - valid acc 0.090\n",
            "Epoch 940: train loss 2.298 - train acc 0.116 - valid loss 2.303 - valid acc 0.090\n",
            "Epoch 950: train loss 2.299 - train acc 0.100 - valid loss 2.307 - valid acc 0.090\n",
            "Epoch 960: train loss 2.301 - train acc 0.110 - valid loss 2.307 - valid acc 0.090\n",
            "Epoch 970: train loss 2.298 - train acc 0.116 - valid loss 2.305 - valid acc 0.090\n",
            "Epoch 980: train loss 2.298 - train acc 0.110 - valid loss 2.303 - valid acc 0.100\n",
            "Epoch 990: train loss 2.299 - train acc 0.106 - valid loss 2.304 - valid acc 0.090\n",
            "Best epoch 6, best acc 0.12\n",
            "Elapsed time (s): 256.02733369999623\n"
          ]
        }
      ],
      "source": [
        "start = timer()\n",
        "lr=1e-3\n",
        "hidden_width = 500\n",
        "n_additional_hidden_layers = 100\n",
        "use_relu = False\n",
        "p_opt = partial(torch.optim.Adam, lr=lr)\n",
        "\n",
        "train_loop(n_features, hidden_width, n_classes, n_additional_hidden_layers, use_relu,\n",
        "           train_dl=small_actual_train_dl, epochs=100, partial_opt=p_opt,\n",
        "           valid_dl=small_valid_dl, verbose=True)\n",
        "end = timer()\n",
        "print(f\"Elapsed time (s): {end-start}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FZt1ciUUnue"
      },
      "source": [
        "Let's compare this with ReLU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTmDU9CZjD9G",
        "outputId": "19daee7f-2fc1-49c7-ff98-d7375edf8ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss 2.362 - train acc 0.084 - valid loss 2.339 - valid acc 0.090\n",
            "Epoch 10: train loss 2.191 - train acc 0.186 - valid loss 2.250 - valid acc 0.150\n",
            "Epoch 20: train loss 1.993 - train acc 0.250 - valid loss 2.225 - valid acc 0.180\n",
            "Epoch 30: train loss 1.781 - train acc 0.354 - valid loss 2.254 - valid acc 0.240\n",
            "Epoch 40: train loss 1.534 - train acc 0.440 - valid loss 2.367 - valid acc 0.230\n",
            "Epoch 50: train loss 1.402 - train acc 0.496 - valid loss 2.585 - valid acc 0.190\n",
            "Epoch 60: train loss 1.284 - train acc 0.538 - valid loss 2.579 - valid acc 0.230\n",
            "Epoch 70: train loss 1.110 - train acc 0.578 - valid loss 2.952 - valid acc 0.160\n",
            "Epoch 80: train loss 0.975 - train acc 0.640 - valid loss 3.158 - valid acc 0.160\n",
            "Epoch 90: train loss 0.883 - train acc 0.712 - valid loss 3.412 - valid acc 0.190\n",
            "Best epoch 52, best acc 0.25\n",
            "Elapsed time (s): 13.78893200001039\n"
          ]
        }
      ],
      "source": [
        "start = timer()\n",
        "lr=1e-3\n",
        "hidden_width = 50\n",
        "n_additional_hidden_layers = 10\n",
        "use_relu = True\n",
        "p_opt = partial(torch.optim.Adam, lr=lr)\n",
        "\n",
        "train_loop(n_features, hidden_width, n_classes, n_additional_hidden_layers, use_relu,\n",
        "           train_dl=small_actual_train_dl, epochs=100, partial_opt=p_opt,\n",
        "           valid_dl=small_valid_dl, verbose=True)\n",
        "end = timer()\n",
        "print(f\"Elapsed time (s): {end-start}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elUlC9zcUvQq"
      },
      "source": [
        "You can see that training of modestly deep networks (for today standards) with the sigmoid function is stuck, while the network using ReLUs increases its performance while training.\n",
        "\n",
        "Let's then define a function to perform hyper-parameter tuning. Since this is a small network we can afford to validate also hyper-parameters defining the architecture, like the `hidden_width` of the layers, or the number of hidden layers. We will also run a loop over optimizers (wrapping learning rates), as usual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sKG3pZ-532ge"
      },
      "outputs": [],
      "source": [
        "def hyperparameter_tuning(n_features, n_classes, train_dl,\n",
        "                          valid_dl, partial_opts, hidden_widths,\n",
        "                          n_additional_hidden_layers_list, epochs=5):\n",
        "\n",
        "  best_valid_acc = 0\n",
        "  best_params = []\n",
        "  best_hyper_params = []\n",
        "\n",
        "  for hidden_width in hidden_widths:\n",
        "    for n_additional_hidden_layers in n_additional_hidden_layers_list:\n",
        "      for partial_opt in partial_opts:\n",
        "        run_valid_acc, params, epoch = train_loop(n_features, hidden_width, n_classes, n_additional_hidden_layers, use_relu=True,\n",
        "                  train_dl=train_dl, epochs=epochs, partial_opt=partial_opt, valid_dl=valid_dl, verbose=False)\n",
        "\n",
        "        if run_valid_acc > best_valid_acc:\n",
        "          best_valid_acc = run_valid_acc\n",
        "          best_params = params\n",
        "          best_hyper_params = [partial_opt, epoch, hidden_width, n_additional_hidden_layers]\n",
        "          print(f\"Improved result: acc {best_valid_acc:.3f}, best_hyper_params {best_hyper_params}\")\n",
        "  return best_hyper_params, best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY_AKgDwVnzC"
      },
      "source": [
        "Then, the usual function to define which combination of optimizers and learning rates we want to validate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5vwlbgDHZ6C",
        "outputId": "4b016982-8a41-4d18-98be-8b5449789d18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[functools.partial(<class 'torch.optim.sgd.SGD'>, lr=0.001, momentum=0.9, nesterov=True),\n",
              " functools.partial(<class 'torch.optim.sgd.SGD'>, lr=0.004, momentum=0.9, nesterov=True),\n",
              " functools.partial(<class 'torch.optim.adam.Adam'>, lr=0.001),\n",
              " functools.partial(<class 'torch.optim.adam.Adam'>, lr=0.004)]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def build_optlist():\n",
        "  lrs = [1e-3, 4e-3]\n",
        "  betas = [0.9]\n",
        "  opts = []\n",
        "  #opts += [partial(torch.optim.SGD, lr=lr) for lr in lrs]\n",
        "  opts += [partial(torch.optim.SGD, lr=lr, momentum=beta, nesterov=True) for lr in lrs for beta in betas]\n",
        "  opts += [partial(torch.optim.Adam, lr=lr) for lr in lrs]\n",
        "  #opts += [partial(torch.optim.RMSprop, lr=lr) for lr in lrs]\n",
        "  return opts\n",
        "\n",
        "build_optlist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7CinT4dVx5a"
      },
      "source": [
        "Let' check everything works on the small `Dataset`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJIwGd6uIUkQ",
        "outputId": "05a960c5-99a1-4f36-cbcc-9bf4704333bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Improved result: acc 0.260, best_hyper_params [functools.partial(<class 'torch.optim.sgd.SGD'>, lr=0.001, momentum=0.9, nesterov=True), 88, 64, 0]\n",
            "Improved result: acc 0.290, best_hyper_params [functools.partial(<class 'torch.optim.sgd.SGD'>, lr=0.004, momentum=0.9, nesterov=True), 65, 64, 0]\n",
            "Improved result: acc 0.310, best_hyper_params [functools.partial(<class 'torch.optim.sgd.SGD'>, lr=0.001, momentum=0.9, nesterov=True), 55, 128, 0]\n",
            "Improved result: acc 0.320, best_hyper_params [functools.partial(<class 'torch.optim.sgd.SGD'>, lr=0.004, momentum=0.9, nesterov=True), 80, 128, 0]\n",
            "Elapsed time (s): 193.476\n",
            "best optimizer functools.partial(<class 'torch.optim.sgd.SGD'>, lr=0.004, momentum=0.9, nesterov=True), best epoch 80,best hidden_width 128, best n_additional_hidden 0\n"
          ]
        }
      ],
      "source": [
        "start=timer()\n",
        "opts = build_optlist()\n",
        "hidden_widths = [64, 128]\n",
        "n_hidden_layers_list = [0,1]\n",
        "best_hyper_params, best_params = hyperparameter_tuning(n_features, n_classes, small_actual_train_dl,\n",
        "                  small_valid_dl, opts, hidden_widths, n_hidden_layers_list, epochs=100)\n",
        "end=timer()\n",
        "print(f\"Elapsed time (s): {end-start:.3f}\")\n",
        "print(f\"best optimizer {best_hyper_params[0]}, best epoch {best_hyper_params[1]},\"\n",
        "      f\"best hidden_width {best_hyper_params[2]}, best n_additional_hidden {best_hyper_params[3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1JYpRlnV4Xi"
      },
      "source": [
        "And then, let's validate on the real `Dataset`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41iJn4dAJRvY",
        "outputId": "f241f8f1-ca9c-466c-851a-23689012ba83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Improved result: acc 0.472, best_hyper_params [functools.partial(<class 'torch.optim.sgd.SGD'>, lr=0.001, momentum=0.9, nesterov=True), 39, 128, 0]\n",
            "Improved result: acc 0.515, best_hyper_params [functools.partial(<class 'torch.optim.sgd.SGD'>, lr=0.004, momentum=0.9, nesterov=True), 34, 128, 0]\n",
            "Improved result: acc 0.522, best_hyper_params [functools.partial(<class 'torch.optim.sgd.SGD'>, lr=0.004, momentum=0.9, nesterov=True), 35, 128, 1]\n",
            "Elapsed time (s): 2962.552\n",
            "best optimizer functools.partial(<class 'torch.optim.sgd.SGD'>, lr=0.004, momentum=0.9, nesterov=True), best epoch 35, best hidden_width 128, best n_additional_hidden 1\n"
          ]
        }
      ],
      "source": [
        "start=timer()\n",
        "opts = build_optlist()\n",
        "hidden_widths = [128]\n",
        "n_hidden_layers_list = [0,1]\n",
        "best_hyper_params, best_params = hyperparameter_tuning(n_features, n_classes,\n",
        "      actual_train_dl, valid_dl, opts, hidden_widths, n_hidden_layers_list, epochs=40)\n",
        "end=timer()\n",
        "print(f\"Elapsed time (s): {end-start:.3f}\")\n",
        "print(f\"best optimizer {best_hyper_params[0]}, best epoch {best_hyper_params[1]}, \"\n",
        "      f\"best hidden_width {best_hyper_params[2]}, best n_additional_hidden {best_hyper_params[3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJdDrnimWBrL"
      },
      "source": [
        "Let's train on the full training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb6B3-IoLvUL"
      },
      "outputs": [],
      "source": [
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l6RNMV7LwBV",
        "outputId": "31c34ea1-2391-415e-8bbd-b4ddad0be3c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss 1.942 - train acc 0.311\n",
            "Epoch 10: train loss 1.412 - train acc 0.503\n",
            "Epoch 20: train loss 1.281 - train acc 0.548\n",
            "Epoch 30: train loss 1.181 - train acc 0.583\n",
            "Elapsed time (s): 311.61791934300027\n"
          ]
        }
      ],
      "source": [
        "start = timer()\n",
        "best_opt = best_hyper_params[0]\n",
        "best_epochs = best_hyper_params[1]\n",
        "_, best_params, best_epoch = train_loop(n_features=n_features,\n",
        "        hidden_width=best_hyper_params[2], n_classes=n_classes,\n",
        "        n_additional_hidden_layers=best_hyper_params[3], use_relu=True,\n",
        "        train_dl=train_dl, epochs=best_epochs, partial_opt=best_opt, verbose=True)\n",
        "end = timer()\n",
        "print(f\"Elapsed time (s): {end-start}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrn0gnLGWLAJ"
      },
      "source": [
        "And test on the full test set. To restore the parameters computed in training, we use the `load_state_dict` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weI1-WB2MBxN",
        "outputId": "4f6d9e35-e4af-495f-f1b9-aa113010fdef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on full test set 0.504, elapsed time (s): 1.580\n"
          ]
        }
      ],
      "source": [
        "nn = TwoPlusLayersNetwork(n_features, best_hyper_params[2], n_classes, best_hyper_params[3])\n",
        "nn.load_state_dict(best_params)\n",
        "\n",
        "start = timer()\n",
        "test_samples = 0\n",
        "test_acc = 0\n",
        "for test_data in test_dl:\n",
        "  test_scores = nn.forward(test_data[0])\n",
        "  test_samples += test_data[0].shape[0]\n",
        "  test_acc += ncorrect(test_scores, test_data[1]).item()\n",
        "test_acc /= test_samples\n",
        "end = timer()\n",
        "print(f\"Accuracy on full test set {test_acc:.3f}, elapsed time (s): {end-start:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J03uNx8HVazi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fft_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05e3a49575ec4f5cb99884756b3be1d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "119b429102b64b92b70e485fec445730": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c042763bc8d47b39331698febf3da11",
            "placeholder": "​",
            "style": "IPY_MODEL_b673b35ac1bb450b98a3579474917b31",
            "value": "100%"
          }
        },
        "1c042763bc8d47b39331698febf3da11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c08781342a548eb9d9ed8a97583caa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e3a49575ec4f5cb99884756b3be1d2",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90ce6a95de24450f8c365a3cfbf4db72",
            "value": 170498071
          }
        },
        "2aa8fd2ddd054b44825b5908f29510db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "787603d3b0b14f91bdf68c45e7eb5fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90ce6a95de24450f8c365a3cfbf4db72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b673b35ac1bb450b98a3579474917b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8430ea02b2c44069a81c467c6d31b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_787603d3b0b14f91bdf68c45e7eb5fa2",
            "placeholder": "​",
            "style": "IPY_MODEL_2aa8fd2ddd054b44825b5908f29510db",
            "value": " 170498071/170498071 [00:04&lt;00:00, 46227481.85it/s]"
          }
        },
        "f7d26e03efd0493687150edb694b61e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_119b429102b64b92b70e485fec445730",
              "IPY_MODEL_1c08781342a548eb9d9ed8a97583caa8",
              "IPY_MODEL_e8430ea02b2c44069a81c467c6d31b1d"
            ],
            "layout": "IPY_MODEL_fcbc3ec15c094c38b4ceb7841dc39011"
          }
        },
        "fcbc3ec15c094c38b4ceb7841dc39011": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
